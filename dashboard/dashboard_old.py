import json
from pathlib import Path

import pandas as pd
import streamlit as st

# ---- ê¸°ë³¸ UI ì„¸íŒ… & ê°„ë‹¨ CSS ----
st.set_page_config(
    page_title="Darkweb Leak Intelligence Dashboard",
    layout="wide"
)

# ì•½ê°„ì˜ ì—¬ë°± / í°íŠ¸ í¬ê¸° ì¡°ì •
st.markdown(
    """
    <style>
    .main > div {
        padding-top: 1rem;
        padding-bottom: 2rem;
    }
    section[data-testid="stSidebar"] > div {
        padding-top: 1rem;
    }
    .small-text {
        font-size: 0.85rem;
        color: #bbbbbb;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ“Š Darkweb Leak Intelligence Dashboard")
st.markdown("í…”ë ˆê·¸ë¨ ê¸°ë°˜ ë‹¤í¬ì›¹ ìœ ì¶œ ì •ë³´ ìë™ ìˆ˜ì§‘ Â· íŒŒì‹± ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ")

DATA_PATH = Path(__file__).resolve().parent.parent / "data" / "leak_records.csv"


@st.cache_data
def load_data():
    try:
        df = pd.read_csv(DATA_PATH)
        # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ datetimeìœ¼ë¡œ ë³€í™˜
        for col in ["collected_at", "posted_at"]:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors="coerce")
        return df
    except Exception as e:
        st.error(f"CSV íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame()


# ---- (ì¤€)ì‹¤ì‹œê°„ ìƒˆë¡œê³ ì¹¨: ë²„íŠ¼ + ì„ íƒì  ìë™ ë¦¬í”„ë ˆì‹œ ----
st.sidebar.header("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨")

manual_refresh = st.sidebar.button("ì§€ê¸ˆ ìƒˆë¡œê³ ì¹¨")

# ì„ íƒ: streamlit-autorefresh ì„¤ì¹˜ ì‹œ ì£¼ê¸°ì  ë¦¬í”„ë ˆì‹œ ì§€ì›
# pip install streamlit-autorefresh
AUTO_REFRESH_ENABLED = False
try:
    from streamlit_autorefresh import st_autorefresh  # type: ignore

    AUTO_REFRESH_ENABLED = True
except Exception:
    AUTO_REFRESH_ENABLED = False

if AUTO_REFRESH_ENABLED:
    interval_seconds = st.sidebar.slider(
        "ìë™ ìƒˆë¡œê³ ì¹¨ ì£¼ê¸°(ì´ˆ)",
        min_value=0,
        max_value=300,
        value=0,
        step=10,
        help="0ì´ë©´ ìë™ ìƒˆë¡œê³ ì¹¨ ì—†ìŒ",
    )
    if interval_seconds > 0:
        st.sidebar.caption("ğŸ’¡ CSVê°€ ê°±ì‹ ë˜ë©´ ì§€ì •í•œ ì£¼ê¸°ë§ˆë‹¤ ìë™ìœ¼ë¡œ ë°˜ì˜ë©ë‹ˆë‹¤.")
        st_autorefresh(interval=interval_seconds * 1000, key="auto-refresh")

if manual_refresh:
    st.experimental_rerun()

df = load_data()
st.write(f"í˜„ì¬ ìˆ˜ì§‘ëœ ë ˆì½”ë“œ ìˆ˜: **{len(df)}**")

if df.empty:
    st.info("data/leak_records.csv íŒŒì¼ì´ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# =========================================
# 1ï¸âƒ£ ê²€ìƒ‰(Search)
# =========================================

st.sidebar.header("ğŸ” ê²€ìƒ‰ / í•„í„°")

search_query = st.sidebar.text_input(
    "í‚¤ì›Œë“œ ê²€ìƒ‰ (ì œëª©, íƒ€ê¹ƒ ì„œë¹„ìŠ¤, ë„ë©”ì¸ ë“±)",
    value="",
    placeholder="ì˜ˆ: vpn, example.com, KR, university ...",
)

filtered = df.copy()

if search_query.strip():
    q = search_query.strip().lower()
    search_cols = [
        col
        for col in [
            "post_title",
            "target_service",
            "domains",
            "source",
            "leak_types",
            "country",
            "threat_claim",
        ]
        if col in filtered.columns
    ]

    if search_cols:
        mask = False
        for col in search_cols:
            mask = mask | filtered[col].astype(str).str.lower().str.contains(
                q, na=False
            )
        filtered = filtered[mask]

# =========================================
# 2ï¸âƒ£ í•„í„°(Filter)
# =========================================

# Source í•„í„°
if "source" in df.columns:
    source_options = sorted(df["source"].dropna().unique())
    selected_sources = st.sidebar.multiselect(
        "Source(ì±„ë„/í¬ëŸ¼) ì„ íƒ",
        options=source_options,
        default=source_options,
    )
    if selected_sources:
        filtered = filtered[filtered["source"].isin(selected_sources)]

# Confidence í•„í„°
if "confidence" in df.columns:
    conf_options = sorted(df["confidence"].fillna("unknown").unique())
    selected_conf = st.sidebar.multiselect(
        "Confidence ì„ íƒ",
        options=conf_options,
        default=conf_options,
    )
    if selected_conf:
        filtered = filtered[filtered["confidence"].isin(selected_conf)]

# Leak types í•„í„°
if "leak_types" in df.columns:
    leak_type_all = set()
    for v in df["leak_types"].dropna().astype(str):
        for t in [x.strip() for x in v.split(",")]:
            if t:
                leak_type_all.add(t)
    leak_type_all = sorted(list(leak_type_all))

    selected_leak_types = st.sidebar.multiselect(
        "Leak Types ì„ íƒ",
        options=leak_type_all,
        default=leak_type_all,
    )
    if selected_leak_types:
        mask = False
        for t in selected_leak_types:
            mask = mask | filtered["leak_types"].astype(str).str.contains(t, na=False)
        filtered = filtered[mask]

# ë‚ ì§œ í•„í„°
if "collected_at" in df.columns:
    min_date = pd.to_datetime(df["collected_at"]).min()
    max_date = pd.to_datetime(df["collected_at"]).max()

    date_range = st.sidebar.date_input(
        "ìˆ˜ì§‘ì¼ ë²”ìœ„(collected_at)",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date,
    )

    if isinstance(date_range, tuple) and len(date_range) == 2:
        start_date, end_date = date_range
        filtered = filtered[
            (filtered["collected_at"] >= pd.to_datetime(start_date))
            & (filtered["collected_at"] <= pd.to_datetime(end_date))
        ]

# =========================================
# 3ï¸âƒ£ ì •ë ¬(Sort)
# =========================================

sort_options = [
    "ìµœì‹  ìˆ˜ì§‘ì¼ ë‚´ë¦¼ì°¨ìˆœ",
    "ìˆ˜ì§‘ì¼ ì˜¤ë¦„ì°¨ìˆœ",
    "ìœ ì¶œ ê·œëª¨(estimated_volume) ë‚´ë¦¼ì°¨ìˆœ",
    "ìœ ì¶œ ê·œëª¨ ì˜¤ë¦„ì°¨ìˆœ",
]

sort_choice = st.sidebar.selectbox("ì •ë ¬ ê¸°ì¤€", sort_options)

if sort_choice == "ìµœì‹  ìˆ˜ì§‘ì¼ ë‚´ë¦¼ì°¨ìˆœ" and "collected_at" in filtered.columns:
    filtered = filtered.sort_values("collected_at", ascending=False)
elif sort_choice == "ìˆ˜ì§‘ì¼ ì˜¤ë¦„ì°¨ìˆœ" and "collected_at" in filtered.columns:
    filtered = filtered.sort_values("collected_at", ascending=True)
elif (
    sort_choice == "ìœ ì¶œ ê·œëª¨(estimated_volume) ë‚´ë¦¼ì°¨ìˆœ"
    and "estimated_volume" in filtered.columns
):
    filtered = filtered.sort_values(
        "estimated_volume", ascending=False, na_position="last"
    )
elif (
    sort_choice == "ìœ ì¶œ ê·œëª¨ ì˜¤ë¦„ì°¨ìˆœ"
    and "estimated_volume" in filtered.columns
):
    filtered = filtered.sort_values(
        "estimated_volume", ascending=True, na_position="last"
    )

st.markdown(f"### ğŸ” í•„í„° ì ìš© í›„ ë ˆì½”ë“œ ìˆ˜: **{len(filtered)}**")

# =========================================
# 4ï¸âƒ£ ê·¸ë˜í”„(Charts)
# =========================================

st.divider()
st.subheader("ğŸ“ˆ ê°„ë‹¨ í†µê³„ ì‹œê°í™”")

col_chart1, col_chart2 = st.columns(2)

if "confidence" in filtered.columns:
    with col_chart1:
        st.markdown("#### Confidence ë¶„í¬")
        conf_counts = filtered["confidence"].fillna("unknown").value_counts()
        st.bar_chart(conf_counts)

if "source" in filtered.columns:
    with col_chart2:
        st.markdown("#### Sourceë³„ ê±´ìˆ˜")
        source_counts = filtered["source"].fillna("Unknown").value_counts()
        st.bar_chart(source_counts)

if "collected_at" in filtered.columns:
    st.markdown("#### ğŸ“† ìˆ˜ì§‘ì¼ ê¸°ì¤€ ê±´ìˆ˜ ì¶”ì´")
    date_counts = (
        filtered.dropna(subset=["collected_at"])
        .groupby(filtered["collected_at"].dt.date)
        .size()
        .rename("count")
    )
    st.line_chart(date_counts)

# =========================================
# 5ï¸âƒ£ ë¦¬ìŠ¤íŠ¸ + ìƒì„¸ ë³´ê¸° + OSINT ë§í¬
# =========================================

st.divider()
st.subheader("ğŸ“„ ìœ ì¶œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸")

main_cols = [
    "collected_at",
    "source",
    "post_title",
    "target_service",
    "domains",
    "estimated_volume",
    "leak_types",
    "confidence",
]
main_cols = [c for c in main_cols if c in filtered.columns]

st.dataframe(
    filtered[main_cols],
    use_container_width=True,
    height=350,
)

st.subheader("ğŸ” ì„ íƒí•œ ë ˆì½”ë“œ ìƒì„¸ ë³´ê¸°")

if len(filtered) > 0:
    idx = st.number_input(
        "ìƒì„¸ë³´ê¸°í•  index ì„ íƒ",
        min_value=0,
        max_value=len(filtered) - 1,
        step=1,
        value=0,
    )
    record = filtered.iloc[int(idx)]

    st.markdown("#### ì£¼ìš” ì •ë³´")
    info_cols = [
        "collected_at",
        "source",
        "post_title",
        "post_id",
        "author",
        "posted_at",
        "target_service",
        "domains",
        "leak_types",
        "estimated_volume",
        "file_formats",
        "country",
        "confidence",
    ]
    for c in info_cols:
        if c in record.index:
            st.write(f"**{c}**: {record[c]}")

    st.markdown("#### Threat / Deal / OSINT Seeds (ì›ë¬¸)")

    for c in ["threat_claim", "deal_terms", "osint_seeds"]:
        if c in record.index and pd.notna(record[c]):
            st.write(f"**{c}**")
            st.code(str(record[c]))

    # ---- ğŸŒ OSINT Quick Links ----
    st.markdown("### ğŸŒ OSINT Quick Links")

    # ë„ë©”ì¸ ê¸°ë°˜ ë§í¬
    domains_str = str(record.get("domains", "") or "")
    domain_list = [
        d.strip() for d in domains_str.replace(";", ",").split(",") if d.strip()
    ]

    if domain_list:
        st.markdown("**ë„ë©”ì¸ ê¸°ë°˜ ë¶„ì„ ë§í¬**")
        for d in domain_list:
            st.markdown(
                f"- `{d}` â†’ "
                f"[Whois](https://who.is/whois/{d})  |  "
                f"[VirusTotal](https://www.virustotal.com/gui/domain/{d})  |  "
                f"[URLScan](https://urlscan.io/domain/{d})"
            )
    else:
        st.caption("ë„ë©”ì¸ ì •ë³´ê°€ ì—†ì–´ ë„ë©”ì¸ ê¸°ë°˜ OSINT ë§í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # osint_seedsê°€ JSON/ë”•ì…”ë„ˆë¦¬ë¼ë©´ ê°€ë…ì„± ìˆê²Œ íŒŒì‹±
    raw_seeds = record.get("osint_seeds", None)
    if pd.notna(raw_seeds):
        try:
            # ë¬¸ìì—´ì¸ ê²½ìš° JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
            if isinstance(raw_seeds, str):
                seeds_obj = json.loads(raw_seeds)
            else:
                seeds_obj = raw_seeds

            if isinstance(seeds_obj, dict):
                st.markdown("**ì¶”ê°€ OSINT Seed í•„ë“œ**")
                st.json(seeds_obj)
        except Exception:
            # ê·¸ëƒ¥ ìœ„ì—ì„œ codeë¡œ ë³´ì—¬ì¤€ ê±¸ë¡œ ì¶©ë¶„
            pass

else:
    st.info("í•„í„° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================================
# 6ï¸âƒ£ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
# =========================================

st.divider()
st.subheader("â¬‡ï¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

csv_bytes = filtered.to_csv(index=False).encode("utf-8")
st.download_button(
    label="í•„í„°ëœ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
    data=csv_bytes,
    file_name="leak_records_filtered.csv",
    mime="text/csv",
)

st.markdown(
    '<p class="small-text">â€» CSVëŠ” í˜„ì¬ ê²€ìƒ‰/í•„í„°/ì •ë ¬ì´ ì ìš©ëœ ìƒíƒœ ê·¸ëŒ€ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.</p>',
    unsafe_allow_html=True,
)
