# app/telegram_RansomFeedNews.py

from datetime import date, datetime
from typing import List
from urllib.parse import urlparse

from .models import IntermediateEvent, LeakRecord


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# URL ë¦¬ìŠ¤íŠ¸ â†’ ë„ë©”ì¸ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ë¡œì»¬ í—¬í¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _extract_domains(urls: List[str]) -> List[str]:
    """
    URL ë¦¬ìŠ¤íŠ¸ì—ì„œ ë„ë©”ì¸ë§Œ ì¶”ì¶œí•˜ì—¬ ì¤‘ë³µ ì œê±°í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤.
    ì˜ˆ:
        ["https://example.com/a", "http://sub.example.com", "https://example.com/b"]
        -> ["example.com", "sub.example.com"]
    """
    domains: List[str] = []

    for u in urls:
        try:
            netloc = urlparse(u).netloc.lower()
        except Exception:
            continue

        if netloc and netloc not in domains:
            domains.append(netloc)

    return domains


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) raw_text â†’ IntermediateEvent
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def parse_RansomFeedNews(
    raw_text: str, message_id=None, message_url=None
) -> IntermediateEvent:
    """
    RansomFeedNews ì±„ë„ ë©”ì‹œì§€ íŒŒì„œ.
    """

    lines = raw_text.splitlines()

    # ê¸°ë³¸ í¬ë§· ì˜ˆì‹œ:
    # ID: 27781
    # âš ï¸ Sun, 07 Dec 2025 14:42:25 CET
    # ğŸ¥· sinobi
    # ğŸ¯ Quality Companies, USA
    # ğŸ”— http://www.ransomfeed.it/index.php?page=post_details&id_post=27781

    # 1) ë‘ ë²ˆì§¸ ì¤„(raw ë‚ ì§œ ì¤„) ì •ë¦¬
    raw_line = lines[1].strip()

    # ì•ì— ë¶™ì€ ì´ëª¨ì§€(âš ï¸, ğŸ“… ë“±) ì œê±°
    # ì•ŒíŒŒë²³ì´ ì‹œì‘ë  ë•Œê¹Œì§€ ì•ë¶€ë¶„ì„ ì˜ë¼ë‚¸ë‹¤.
    while raw_line and not raw_line[0].isalpha():
        raw_line = raw_line[1:].lstrip()

    # 2) ëì— ë¶™ì€ íƒ€ì„ì¡´(UTC, CET, GMT ë“±) ì œê±°
    parts = raw_line.split()
    if parts and parts[-1].isupper():
        # ë§ˆì§€ë§‰ í† í°ì´ ì „ë¶€ ëŒ€ë¬¸ìë©´ íƒ€ì„ì¡´ìœ¼ë¡œ ë³´ê³  ì œê±°
        raw_line = " ".join(parts[:-1])

    # ì´ì œ raw_lineì€ "Sun, 07 Dec 2025 14:42:25" í˜•íƒœê°€ ë¨
    published_date_text = datetime.strptime(
        raw_line, "%a, %d %b %Y %H:%M:%S"
    ).date()

    # 3) ê³µê²© ê·¸ë£¹ / í”¼í•´ì / URL
    group = lines[2][2:-1]            # "ğŸ¥· sinobi" â†’ "sinobi"
    victim = lines[3][2:-1]           # "ğŸ¯ Quality Companies, USA" â†’ "Quality Companies, USA"
    urls: List[str] = [lines[4][2:]]  # "ğŸ”— http://..." â†’ "http://..."

    return IntermediateEvent(
        source_channel="@RansomFeedNews",
        raw_text=raw_text,
        message_id=message_id,
        message_url=message_url,
        group_name=group,
        victim_name=victim,
        published_at_text=published_date_text,
        urls=urls,
        tags=[],
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) IntermediateEvent â†’ LeakRecord ë³€í™˜ê¸°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def intermediate_to_leakrecord(event: IntermediateEvent) -> LeakRecord:
    """
    íŒŒì‹±ëœ IntermediateEvent â†’ LeakRecord í‘œì¤€ êµ¬ì¡° ë³€í™˜
    """

    # URL ë¦¬ìŠ¤íŠ¸ì—ì„œ ë„ë©”ì¸ë§Œ ì¶”ì¶œ
    domains = _extract_domains(event.urls)

    return LeakRecord(
        collected_at=date.today(),
        source=event.source_channel,
        post_title=f"{event.group_name or ''} â†’ {event.victim_name or ''}",
        post_id=str(event.message_id) if event.message_id else "",
        author=None,
        posted_at=event.published_at_text,
        leak_types=[],
        estimated_volume=None,
        file_formats=[],
        target_service=event.victim_name,
        domains=domains,
        country=None,
        threat_claim=event.group_name,
        deal_terms=None,
        confidence="medium",
        screenshot_refs=[],
        osint_seeds={"urls": event.urls},
    )
